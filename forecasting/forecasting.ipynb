{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Idea is to forecast 1-6 hours til the 48 hours with lookback from 7 days to 30 days.",
   "id": "a2f2119a804ae952"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-19T18:15:13.628308Z",
     "start_time": "2025-08-19T18:15:12.455990Z"
    }
   },
   "source": [
    "# =========================\n",
    "# PatchTST forecasting pipeline (Darts)\n",
    "# =========================\n",
    "# If running in a notebook, run this cell once.\n",
    "# !pip -q install \"u8darts[torch]>=0.30.0\" torch pytorch-lightning --upgrade\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "\n",
    "# Darts core\n",
    "from darts import TimeSeries\n",
    "from darts.models import PatchTSTModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import mape, rmse, mae\n",
    "\n",
    "# -----------------\n",
    "# CONFIG\n",
    "# -----------------\n",
    "DATA_CSV = \"data/combined_hourly_dataset.csv\"   # path to your merged dataset\n",
    "TARGET_COL = \"close\"                             # what we forecast\n",
    "LOOKBACK_H = 168                                 # 7 days of history\n",
    "HORIZON_H  = 24                                  # forecast next 24 hours\n",
    "VAL_HOURS  = 24 * 30                             # last 30 days for validation\n",
    "N_EPOCHS   = 50                                  # training epochs (raise to 100+ for better accuracy)\n",
    "BATCH_SIZE = 64\n",
    "RANDOM_SEED = 42\n",
    "OUT_DIR = Path(\"data/forecasts\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -----------------\n",
    "# 1) Load & preprocess\n",
    "# -----------------\n",
    "df = pd.read_csv(DATA_CSV, parse_dates=[\"timestamp\"])\n",
    "df = df.set_index(\"timestamp\").sort_index()\n",
    "# keep hourly freq label (use lowercase 'h' to avoid FutureWarning)\n",
    "df = df.asfreq(\"h\")\n",
    "\n",
    "# Drop clearly non-numeric columns (e.g., symbol/exchange) and use numeric features only\n",
    "non_numeric = [c for c in df.columns if not np.issubdtype(df[c].dtype, np.number)]\n",
    "df_num = df.drop(columns=non_numeric)\n",
    "\n",
    "# Basic hygiene: forward-fill tiny gaps, then still-missing -> drop rows at the very start if needed\n",
    "df_num = df_num.ffill().bfill()\n",
    "\n",
    "# Target & feature split\n",
    "assert TARGET_COL in df_num.columns, f\"{TARGET_COL=} not in columns!\"\n",
    "feature_cols = [c for c in df_num.columns if c != TARGET_COL]\n",
    "print(f\"Using {len(feature_cols)} past covariate features.\")\n",
    "\n",
    "# -----------------\n",
    "# 2) Build Darts TimeSeries\n",
    "# -----------------\n",
    "series_all = TimeSeries.from_dataframe(df_num, value_cols=[TARGET_COL])\n",
    "past_covs_all = TimeSeries.from_dataframe(df_num[feature_cols]) if feature_cols else None\n",
    "\n",
    "# Train/val split by time (no leakage)\n",
    "split_time = series_all.end_time() - pd.Timedelta(hours=VAL_HOURS)\n",
    "series_train, series_val = series_all.split_after(split_time)\n",
    "if past_covs_all is not None:\n",
    "    past_covs_train, past_covs_val = past_covs_all.split_after(split_time)\n",
    "else:\n",
    "    past_covs_train = past_covs_val = None\n",
    "\n",
    "# -----------------\n",
    "# 3) Scaling (fit on train only)\n",
    "# -----------------\n",
    "y_scaler = Scaler()\n",
    "series_train_scaled = y_scaler.fit_transform(series_train)\n",
    "series_val_scaled   = y_scaler.transform(series_val)\n",
    "series_all_scaled   = y_scaler.transform(series_all)\n",
    "\n",
    "if past_covs_all is not None:\n",
    "    x_scaler = Scaler()\n",
    "    past_covs_train_scaled = x_scaler.fit_transform(past_covs_train)\n",
    "    past_covs_val_scaled   = x_scaler.transform(past_covs_val)\n",
    "    past_covs_all_scaled   = x_scaler.transform(past_covs_all)\n",
    "else:\n",
    "    past_covs_train_scaled = past_covs_val_scaled = past_covs_all_scaled = None\n",
    "\n",
    "# -----------------\n",
    "# 4) Define PatchTST\n",
    "# -----------------\n",
    "def pick_device():\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    try:\n",
    "        import torch.backends.mps as mps\n",
    "        if mps.is_available():\n",
    "            return \"mps\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    return \"cpu\"\n",
    "\n",
    "device = pick_device()\n",
    "print(f\"Using torch device: {device}\")\n",
    "\n",
    "model = PatchTSTModel(\n",
    "    input_chunk_length=LOOKBACK_H,\n",
    "    output_chunk_length=HORIZON_H,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    random_state=RANDOM_SEED,\n",
    "    d_model=64,             # model width\n",
    "    n_heads=4,\n",
    "    num_layers=3,\n",
    "    dropout=0.1,\n",
    "    kernel_size=25,         # as in PatchTST paper\n",
    "    optimizer_kwargs={\"lr\": 1e-3},\n",
    "    torch_device=device,\n",
    "    pl_trainer_kwargs={\n",
    "        \"accelerator\": \"gpu\" if device == \"cuda\" else (\"mps\" if device == \"mps\" else \"cpu\"),\n",
    "        \"devices\": 1,\n",
    "        \"logger\": False,\n",
    "        \"enable_checkpointing\": True,\n",
    "    },\n",
    ")\n",
    "\n",
    "# -----------------\n",
    "# 5) Fit\n",
    "# -----------------\n",
    "model.fit(\n",
    "    series=series_train_scaled,\n",
    "    past_covariates=past_covs_train_scaled,\n",
    "    val_series=series_val_scaled,\n",
    "    val_past_covariates=past_covs_val_scaled,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# -----------------\n",
    "# 6) Rolling backtest (walk-forward)\n",
    "# -----------------\n",
    "# Start backtesting after we have enough history for the lookback\n",
    "backtest_start = max(series_train_scaled.start_time() + pd.Timedelta(hours=LOOKBACK_H),\n",
    "                     series_train_scaled.end_time() - pd.Timedelta(hours=VAL_HOURS))\n",
    "\n",
    "hist_fc = model.historical_forecasts(\n",
    "    series=series_all_scaled,\n",
    "    past_covariates=past_covs_all_scaled,\n",
    "    start=backtest_start,\n",
    "    forecast_horizon=HORIZON_H,\n",
    "    stride=HORIZON_H,     # non-overlapping blocks for clarity (set to 1 for tighter evaluation)\n",
    "    retrain=False,        # set True for strict backtesting (slower)\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Align & inverse transform forecasts for metrics\n",
    "hist_fc = TimeSeries.from_series(hist_fc.pd_series()) if isinstance(hist_fc, TimeSeries) else hist_fc\n",
    "hist_fc_y = y_scaler.inverse_transform(hist_fc)\n",
    "actual_y  = series_all.slice_intersect(hist_fc_y.time_index)\n",
    "actual_y  = y_scaler.inverse_transform(actual_y)\n",
    "\n",
    "print(\"\\n--- Backtest metrics (validation region) ---\")\n",
    "print(f\"MAE : {mae(actual_y, hist_fc_y):.4f}\")\n",
    "print(f\"RMSE: {rmse(actual_y, hist_fc_y):.4f}\")\n",
    "print(f\"MAPE: {mape(actual_y, hist_fc_y):.4f}%\")\n",
    "\n",
    "# -----------------\n",
    "# 7) Forecast the next HORIZON_H hours\n",
    "# -----------------\n",
    "future_fc_scaled = model.predict(\n",
    "    n=HORIZON_H,\n",
    "    series=series_all_scaled,\n",
    "    past_covariates=past_covs_all_scaled,\n",
    ")\n",
    "\n",
    "future_fc = y_scaler.inverse_transform(future_fc_scaled)\n",
    "\n",
    "# Save forecast\n",
    "pred_df = future_fc.pd_series().to_frame(name=f\"predict_{TARGET_COL}\")\n",
    "pred_df.index.name = \"timestamp\"\n",
    "pred_path = OUT_DIR / f\"patchtst_forecast_{HORIZON_H}h.csv\"\n",
    "pred_df.to_csv(pred_path)\n",
    "print(f\"\\nSaved next {HORIZON_H}h forecast → {pred_path}\")\n",
    "\n",
    "# Optional: also dump last train/val portion + prediction for quick plotting elsewhere\n",
    "tail_df = df_num[[TARGET_COL]].iloc[-(LOOKBACK_H + HORIZON_H + 200):].copy()\n",
    "tail_df[\"prediction\"] = np.nan\n",
    "tail_df.loc[pred_df.index, \"prediction\"] = pred_df[f\"predict_{TARGET_COL}\"]\n",
    "tail_dump = OUT_DIR / \"patchtst_tail_with_forecast.csv\"\n",
    "tail_df.to_csv(tail_dump)\n",
    "print(f\"Saved tail+forecast slice → {tail_dump}\")"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PatchTSTModel' from 'darts.models' (/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/darts/models/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 18\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Darts core\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mdarts\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m TimeSeries\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mdarts\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m PatchTSTModel\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mdarts\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Scaler\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mdarts\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m mape, rmse, mae\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'PatchTSTModel' from 'darts.models' (/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/darts/models/__init__.py)"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "809d8f3125c45a20"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
