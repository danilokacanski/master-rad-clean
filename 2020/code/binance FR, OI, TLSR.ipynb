{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-19T09:42:07.561383Z",
     "start_time": "2025-08-19T09:40:41.904955Z"
    }
   },
   "source": [
    "# Binance UM Futures â€” robust hourly fetch (handles '-1130 startTime invalid')\n",
    "\n",
    "import pandas as pd\n",
    "import requests, time, math\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "SYMBOL      = \"BTCUSDT\"\n",
    "START_DATE  = datetime(2020, 1, 1, tzinfo=timezone.utc)   # ask early; code will skip forward if invalid\n",
    "END_DATE    = datetime.now(timezone.utc)\n",
    "\n",
    "OUT_ROOT    = Path(\"../data/\")\n",
    "RAW_DIR     = OUT_ROOT / \"derivatives_raw\"\n",
    "FEAT_DIR    = OUT_ROOT / \"derivatives_features\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FEAT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FAPI = \"https://fapi.binance.com\"                 # funding\n",
    "DATA = \"https://fapi.binance.com/futures/data\"    # OI & ratios\n",
    "REQ_TIMEOUT = 30\n",
    "SLEEP = 0.25\n",
    "\n",
    "def _to_ms(dt): return int(dt.timestamp() * 1000)\n",
    "\n",
    "def _is_binance_1130(resp):\n",
    "    try:\n",
    "        j = resp.json()\n",
    "    except Exception:\n",
    "        return False\n",
    "    return isinstance(j, dict) and j.get(\"code\") == -1130\n",
    "\n",
    "def _window_iter(start_dt, end_dt, days):\n",
    "    cur = start_dt\n",
    "    delta = timedelta(days=days)\n",
    "    while cur <= end_dt:\n",
    "        win_end = min(cur + delta, end_dt)\n",
    "        yield cur, win_end\n",
    "        # advance 1 ms past win_end to avoid overlap\n",
    "        cur = (win_end + timedelta(milliseconds=1))\n",
    "\n",
    "# -------- Funding (8h native) uses start+end and is happy with long ranges --------\n",
    "def get_funding(symbol=SYMBOL, start=START_DATE, end=END_DATE, sleep=SLEEP):\n",
    "    url = f\"{FAPI}/fapi/v1/fundingRate\"\n",
    "    out = []\n",
    "    cursor = start\n",
    "    while cursor <= end:\n",
    "        # 90d window is safe for this endpoint\n",
    "        win_end = min(cursor + timedelta(days=90), end)\n",
    "        params = {\n",
    "            \"symbol\": symbol,\n",
    "            \"startTime\": _to_ms(cursor),\n",
    "            \"endTime\": _to_ms(win_end),\n",
    "            \"limit\": 1000\n",
    "        }\n",
    "        r = requests.get(url, params=params, timeout=REQ_TIMEOUT)\n",
    "        if _is_binance_1130(r):\n",
    "            # Move forward (symbol might not have data that early)\n",
    "            cursor = cursor + timedelta(days=90)\n",
    "            time.sleep(sleep)\n",
    "            continue\n",
    "        r.raise_for_status()\n",
    "        batch = r.json()\n",
    "        if not batch:\n",
    "            # no more data in this window; jump to next window\n",
    "            cursor = win_end + timedelta(milliseconds=1)\n",
    "            time.sleep(sleep)\n",
    "            continue\n",
    "        out.extend(batch)\n",
    "        last_ms = batch[-1][\"fundingTime\"]\n",
    "        cursor = datetime.fromtimestamp(last_ms/1000, tz=timezone.utc) + timedelta(milliseconds=1)\n",
    "        time.sleep(sleep)\n",
    "\n",
    "    df = pd.DataFrame(out)\n",
    "    if df.empty: return df\n",
    "    df[\"fundingTime\"] = pd.to_datetime(df[\"fundingTime\"], unit=\"ms\", utc=True)\n",
    "    for c in [\"fundingRate\",\"markPrice\"]:\n",
    "        if c in df: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    keep = [c for c in [\"symbol\",\"fundingTime\",\"fundingRate\",\"markPrice\"] if c in df]\n",
    "    return df[keep].sort_values(\"fundingTime\").reset_index(drop=True)\n",
    "\n",
    "# -------- Helper for endpoints that REQUIRE startTime & endTime and reject too-early times --------\n",
    "def _windowed_get_with_skip(url, base_params, time_key, start_dt, end_dt, window_days=30, limit=500, sleep=SLEEP):\n",
    "    out = []\n",
    "    for ws, we in _window_iter(start_dt, end_dt, window_days):\n",
    "        params = dict(base_params)\n",
    "        params.update({\"startTime\": _to_ms(ws), \"endTime\": _to_ms(we), \"limit\": limit})\n",
    "        r = requests.get(url, params=params, timeout=REQ_TIMEOUT)\n",
    "        if _is_binance_1130(r):\n",
    "            # This whole window starts before supported history; skip it forward\n",
    "            time.sleep(sleep)\n",
    "            continue\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        batch = data if isinstance(data, list) else data.get(\"data\", []) or []\n",
    "        if not batch:\n",
    "            # Nothing here; continue to next window\n",
    "            time.sleep(sleep)\n",
    "            continue\n",
    "        out.extend(batch)\n",
    "        time.sleep(sleep)\n",
    "    # de-dup in case of any boundary overlaps\n",
    "    return out\n",
    "\n",
    "# -------- Open Interest (1h) --------\n",
    "def get_open_interest(symbol=SYMBOL, start=START_DATE, end=END_DATE, period=\"1h\"):\n",
    "    \"\"\"\n",
    "    /futures/data/openInterestHist\n",
    "    Accepts symbol, period, startTime, endTime, limit (<=500).\n",
    "    We walk in 30d windows and skip invalid early ranges automatically.\n",
    "    \"\"\"\n",
    "    url = f\"{DATA}/openInterestHist\"\n",
    "    rows = _windowed_get_with_skip(\n",
    "        url, {\"symbol\": symbol, \"period\": period},\n",
    "        time_key=\"timestamp\",\n",
    "        start_dt=start, end_dt=end,\n",
    "        window_days=30, limit=500, sleep=SLEEP\n",
    "    )\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty: return df\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\", utc=True)\n",
    "    for c in [\"sumOpenInterest\",\"sumOpenInterestValue\"]:\n",
    "        if c in df: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    keep = [c for c in [\"symbol\",\"timestamp\",\"sumOpenInterest\",\"sumOpenInterestValue\"] if c in df]\n",
    "    return df[keep].drop_duplicates(subset=[\"timestamp\"]).sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "# -------- Taker long/short ratio (1h) --------\n",
    "def get_taker_ratio(symbol=SYMBOL, start=START_DATE, end=END_DATE, period=\"1h\"):\n",
    "    \"\"\"\n",
    "    /futures/data/topLongShortAccountRatio\n",
    "    Same behavior as OI. Use 30d windows + auto-skip when -1130 occurs.\n",
    "    \"\"\"\n",
    "    url = f\"{DATA}/topLongShortAccountRatio\"\n",
    "    rows = _windowed_get_with_skip(\n",
    "        url, {\"symbol\": symbol, \"period\": period},\n",
    "        time_key=\"timestamp\",\n",
    "        start_dt=start, end_dt=end,\n",
    "        window_days=30, limit=500, sleep=SLEEP\n",
    "    )\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty: return df\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\", utc=True)\n",
    "    for c in [\"longShortRatio\",\"longAccount\",\"shortAccount\"]:\n",
    "        if c in df: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    keep = [c for c in [\"symbol\",\"timestamp\",\"longShortRatio\",\"longAccount\",\"shortAccount\"] if c in df]\n",
    "    return df[keep].drop_duplicates(subset=[\"timestamp\"]).sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "# ---------------- Run & Save RAW ----------------\n",
    "print(\"Fetching funding (8h native)...\")\n",
    "funding_raw = get_funding()\n",
    "print(\"Funding rows:\", len(funding_raw))\n",
    "\n",
    "print(\"Fetching open interest (1h)...\")\n",
    "oi_raw = get_open_interest(period=\"1h\")\n",
    "print(\"Open interest rows:\", len(oi_raw))\n",
    "\n",
    "print(\"Fetching taker long/short ratio (1h)...\")\n",
    "taker_raw = get_taker_ratio(period=\"1h\")\n",
    "print(\"Taker rows:\", len(taker_raw))\n",
    "\n",
    "funding_raw.to_csv(RAW_DIR / f\"binance_funding_{SYMBOL}.csv\", index=False)\n",
    "oi_raw.to_csv(RAW_DIR / f\"binance_open_interest_{SYMBOL}_1h.csv\", index=False)\n",
    "taker_raw.to_csv(RAW_DIR / f\"binance_taker_longshort_{SYMBOL}_1h.csv\", index=False)\n",
    "\n",
    "# ---------------- Build hourly features ----------------\n",
    "# Funding -> hourly grid via ffill (max 8H)\n",
    "if not funding_raw.empty:\n",
    "    funding_h = (\n",
    "        funding_raw.rename(columns={\"fundingTime\":\"timestamp\"})\n",
    "        .set_index(\"timestamp\").sort_index()\n",
    "        .asfreq(\"1H\").ffill(limit=8).reset_index()\n",
    "    )\n",
    "    if \"fundingRate\" in funding_h:\n",
    "        funding_h[\"funding_annualized_pct\"] = funding_h[\"fundingRate\"] * 3 * 365 * 100\n",
    "else:\n",
    "    funding_h = pd.DataFrame(columns=[\"timestamp\",\"symbol\",\"fundingRate\",\"markPrice\",\"funding_annualized_pct\"])\n",
    "\n",
    "# OI hourly + diffs\n",
    "if not oi_raw.empty:\n",
    "    oi_h = oi_raw.copy()\n",
    "    oi_h[\"oi_change\"] = oi_h[\"sumOpenInterest\"].diff()\n",
    "    oi_h[\"oi_value_change\"] = oi_h[\"sumOpenInterestValue\"].diff()\n",
    "else:\n",
    "    oi_h = pd.DataFrame(columns=[\"timestamp\",\"symbol\",\"sumOpenInterest\",\"sumOpenInterestValue\",\"oi_change\",\"oi_value_change\"])\n",
    "\n",
    "# Taker hourly + shares\n",
    "if not taker_raw.empty:\n",
    "    taker_h = taker_raw.copy()\n",
    "    if \"longShortRatio\" in taker_h:\n",
    "        taker_h[\"long_share\"]  = taker_h[\"longShortRatio\"] / (1.0 + taker_h[\"longShortRatio\"])\n",
    "        taker_h[\"short_share\"] = 1.0 - taker_h[\"long_share\"]\n",
    "else:\n",
    "    taker_h = pd.DataFrame(columns=[\"timestamp\",\"symbol\",\"longShortRatio\",\"longAccount\",\"shortAccount\",\"long_share\",\"short_share\"])\n",
    "\n",
    "# Merge to hourly index\n",
    "hourly_index = pd.date_range(START_DATE, END_DATE, freq=\"1H\", tz=\"UTC\")\n",
    "feat = pd.DataFrame(index=hourly_index)\n",
    "\n",
    "def idx(df): return df.set_index(\"timestamp\").sort_index()\n",
    "\n",
    "if not funding_h.empty:\n",
    "    feat = feat.join(idx(funding_h)[[\"fundingRate\",\"funding_annualized_pct\",\"markPrice\"]], how=\"left\")\n",
    "if not oi_h.empty:\n",
    "    feat = feat.join(idx(oi_h)[[\"sumOpenInterest\",\"sumOpenInterestValue\",\"oi_change\",\"oi_value_change\"]], how=\"left\")\n",
    "if not taker_h.empty:\n",
    "    cols = [c for c in [\"longShortRatio\",\"longAccount\",\"shortAccount\",\"long_share\",\"short_share\"] if c in taker_h]\n",
    "    feat = feat.join(idx(taker_h)[cols], how=\"left\")\n",
    "\n",
    "feat[\"symbol\"] = SYMBOL\n",
    "feat = feat.reset_index().rename(columns={\"index\":\"timestamp\"}).sort_values(\"timestamp\")\n",
    "\n",
    "# light ffill for tiny gaps\n",
    "for c in [\"fundingRate\",\"funding_annualized_pct\",\"markPrice\",\n",
    "          \"sumOpenInterest\",\"sumOpenInterestValue\",\"oi_change\",\"oi_value_change\",\n",
    "          \"longShortRatio\",\"longAccount\",\"shortAccount\",\"long_share\",\"short_share\"]:\n",
    "    if c in feat: feat[c] = feat[c].ffill(limit=6)\n",
    "\n",
    "feat_csv = FEAT_DIR / f\"binance_derivatives_features_{SYMBOL}_1h.csv\"\n",
    "feat.to_csv(feat_csv, index=False)\n",
    "print(f\"Saved FEATURES: {feat_csv}  ({len(feat)} rows)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching funding (8h native)...\n",
      "Funding rows: 6173\n",
      "Fetching open interest (1h)...\n",
      "Open interest rows: 418\n",
      "Fetching taker long/short ratio (1h)...\n",
      "Taker rows: 418\n",
      "Saved FEATURES: ../data/derivatives_features/binance_derivatives_features_BTCUSDT_1h.csv  (49378 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/yhx353f17tj_1s1dj9_gw3x80000gn/T/ipykernel_19497/1912326733.py:170: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  .asfreq(\"1H\").ffill(limit=8).reset_index()\n",
      "/var/folders/tz/yhx353f17tj_1s1dj9_gw3x80000gn/T/ipykernel_19497/1912326733.py:195: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  hourly_index = pd.date_range(START_DATE, END_DATE, freq=\"1H\", tz=\"UTC\")\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e8ac0033dfbecd9c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
