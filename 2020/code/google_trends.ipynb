{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Google Trends (daily, 2020 -> today) for BTC & crypto — robust against 429\n",
    "\n",
    "from pytrends.request import TrendReq\n",
    "import pytrends.exceptions as pte\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pathlib import Path\n",
    "import time, random\n",
    "\n",
    "# -------- config --------\n",
    "KEYWORDS    = [\"Bitcoin\", \"BTC\", \"crypto\"]\n",
    "START_DATE  = pd.Timestamp(\"2020-01-01\", tz=\"UTC\")\n",
    "END_DATE    = pd.Timestamp(datetime.now(timezone.utc).date(), tz=\"UTC\")\n",
    "CHUNK_DAYS  = 150          # keep ≤270 for daily; smaller chunk = fewer 429s\n",
    "BASE_PAUSE  = 3.5          # base delay between requests (seconds)\n",
    "MAX_RETRIES = 6            # per request/window\n",
    "OUT_DIR     = Path(\"../data/google-trends/\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "# ------------------------\n",
    "\n",
    "def new_client():\n",
    "    # Disable pytrends' urllib3 Retry to avoid the method_whitelist arg,\n",
    "    # we handle retries/backoff ourselves in _iot_with_retry().\n",
    "    return TrendReq(\n",
    "        hl=\"en-US\",\n",
    "        tz=0,\n",
    "        retries=0,            # <-- was 2\n",
    "        backoff_factor=0.0,   # <-- was 0.4\n",
    "        timeout=(5, 60),\n",
    "        requests_args={\"headers\": {\"User-Agent\": \"Mozilla/5.0\"}}\n",
    "    )\n",
    "\n",
    "pytrends = new_client()\n",
    "\n",
    "def _pause(extra=0.0):\n",
    "    # small random jitter helps avoid synchronized limits\n",
    "    time.sleep(BASE_PAUSE + extra + random.uniform(0.3, 1.0))\n",
    "\n",
    "def _iot_with_retry(client, timeframe, kw):\n",
    "    \"\"\"interest_over_time with retries, exponential backoff, and session refresh on 429.\"\"\"\n",
    "    delay = 1.0\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            client.build_payload([kw], timeframe=timeframe, geo=\"\")\n",
    "            df = client.interest_over_time()\n",
    "            return df\n",
    "        except pte.TooManyRequestsError:\n",
    "            # backoff + refresh cookie/session\n",
    "            wait = delay + random.uniform(0.25, 0.75)\n",
    "            print(f\"[429] backoff {attempt}/{MAX_RETRIES} — sleeping {wait:.1f}s\")\n",
    "            time.sleep(wait)\n",
    "            delay *= 1.8\n",
    "            # re-create client every couple attempts to rotate cookies\n",
    "            if attempt % 2 == 0:\n",
    "                globals()[\"pytrends\"] = new_client()\n",
    "                client = globals()[\"pytrends\"]\n",
    "        except pte.ResponseError as e:\n",
    "            # transient HTTP issues — brief backoff then retry\n",
    "            wait = delay\n",
    "            print(f\"[WARN] ResponseError attempt {attempt}: {e}; sleep {wait:.1f}s\")\n",
    "            time.sleep(wait)\n",
    "            delay *= 1.8\n",
    "    # final try; if it still fails, return empty frame (caller will handle)\n",
    "    try:\n",
    "        client.build_payload([kw], timeframe=timeframe, geo=\"\")\n",
    "        return client.interest_over_time()\n",
    "    except Exception as e:\n",
    "        print(f\"[FAIL] giving up on timeframe {timeframe} for {kw}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def fetch_daily_keyword(keyword: str, start: pd.Timestamp, end: pd.Timestamp) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Pull daily interest for `keyword` using overlapping windows and stitch with scaling.\n",
    "    Returns a Series indexed by UTC date, name=keyword.\n",
    "    \"\"\"\n",
    "    series_list = []\n",
    "    t0 = start\n",
    "\n",
    "    while t0 < end:\n",
    "        t1 = min(t0 + timedelta(days=CHUNK_DAYS), end)\n",
    "        tf = f\"{t0.date()} {t1.date()}\"\n",
    "\n",
    "        df = _iot_with_retry(pytrends, tf, keyword)\n",
    "        if df.empty or keyword not in df.columns:\n",
    "            print(f\"[WARN] No data for window {tf} / {keyword}\")\n",
    "            t0 = t1\n",
    "            _pause()\n",
    "            continue\n",
    "\n",
    "        s = df[keyword].copy()\n",
    "        # ensure UTC-normalized daily index\n",
    "        s.index = pd.to_datetime(s.index).tz_localize(\"UTC\", nonexistent=\"shift_forward\", ambiguous=\"NaT\").normalize()\n",
    "        series_list.append(s)\n",
    "\n",
    "        t0 = t1\n",
    "        _pause()\n",
    "\n",
    "    if not series_list:\n",
    "        return pd.Series(name=keyword, dtype=\"float64\")\n",
    "\n",
    "    # stitch windows using last-overlap scaling\n",
    "    stitched = series_list[0]\n",
    "    for nxt in series_list[1:]:\n",
    "        overlap = stitched.index.intersection(nxt.index)\n",
    "        if len(overlap) > 0:\n",
    "            anchor = overlap[-1]\n",
    "            a, b = stitched.loc[anchor], nxt.loc[anchor]\n",
    "            scale = (a / b) if (b not in (0, None) and b != 0) else 1.0\n",
    "        else:\n",
    "            scale = 1.0\n",
    "            if len(stitched) and len(nxt):\n",
    "                a, b = stitched.iloc[-1], nxt.iloc[0]\n",
    "                if b not in (0, None) and b != 0:\n",
    "                    scale = a / b\n",
    "\n",
    "        nxt_scaled = nxt * scale\n",
    "        stitched = pd.concat([stitched[~stitched.index.isin(nxt_scaled.index)], nxt_scaled]).sort_index()\n",
    "\n",
    "    stitched = stitched.loc[(stitched.index >= START_DATE) & (stitched.index <= END_DATE)]\n",
    "    stitched.name = keyword\n",
    "    return stitched.astype(\"float64\")\n",
    "\n",
    "# ---- fetch all keywords ----\n",
    "all_series = []\n",
    "for kw in KEYWORDS:\n",
    "    print(f\"Fetching daily trends for: {kw}\")\n",
    "    s = fetch_daily_keyword(kw, START_DATE, END_DATE)\n",
    "    if s.empty:\n",
    "        print(f\"[WARN] Empty series for {kw}\")\n",
    "        continue\n",
    "    s.to_frame().to_csv(OUT_DIR / f\"google_trends_{kw.lower().replace(' ', '_')}_daily.csv\")\n",
    "    all_series.append(s)\n",
    "\n",
    "# ---- combined wide CSV ----\n",
    "if all_series:\n",
    "    wide = pd.concat(all_series, axis=1).sort_index()\n",
    "    wide.index.name = \"date\"\n",
    "    out_path = OUT_DIR / \"google_trends_btc_crypto_daily_wide.csv\"\n",
    "    wide.to_csv(out_path)\n",
    "    print(f\"Saved combined wide CSV -> {out_path} ({len(wide)} rows, {wide.shape[1]} cols)\")\n",
    "    display(wide.tail())\n",
    "else:\n",
    "    print(\"No series fetched.\")"
   ],
   "id": "5bcd101919c133e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
